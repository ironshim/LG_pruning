{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks, 19`ICLR\n",
    "===\n",
    "modified from https://github.com/rahulvigneswaran/Lottery-Ticket-Hypothesis-in-Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "import seaborn as sns\n",
    "import torch.nn.init as init\n",
    "import pickle\n",
    "\n",
    "# Custom Libraries\n",
    "import utils\n",
    "\n",
    "# Tensorboard initialization\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Plotting Style\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\",default= 1.2e-3, type=float, help=\"Learning rate\")\n",
    "parser.add_argument(\"--batch_size\", default=128, type=int)\n",
    "parser.add_argument(\"--start_iter\", default=0, type=int)\n",
    "parser.add_argument(\"--end_iter\", default=10, type=int)\n",
    "parser.add_argument(\"--print_freq\", default=1, type=int)\n",
    "parser.add_argument(\"--valid_freq\", default=1, type=int)\n",
    "parser.add_argument(\"--resume\", action=\"store_true\")\n",
    "parser.add_argument(\"--prune_type\", default=\"lt\", type=str, help=\"lt | reinit\")\n",
    "parser.add_argument(\"--gpu\", default=\"0\", type=str)\n",
    "parser.add_argument(\"--dataset\", default=\"cifar10\", type=str, help=\"mnist | cifar10 | fashionmnist | cifar100\")\n",
    "parser.add_argument(\"--arch_type\", default=\"resnet18\", type=str, help=\"fc1 | lenet5 | alexnet | vgg16 | resnet18 | densenet121\")\n",
    "parser.add_argument(\"--prune_percent\", default=10, type=int, help=\"Pruning percent\")\n",
    "parser.add_argument(\"--prune_iterations\", default=5, type=int, help=\"Pruning iterations count\")\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=args.gpu\n",
    "\n",
    "\n",
    "#FIXME resample\n",
    "resample = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prune_type == \"lt\" refers to Lottery Ticket Hypothesis while \"reinit\" refers to reinitialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reinit = True if args.prune_type==\"reinit\" else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again, we're going to use CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "traindataset = datasets.CIFAR10('../datasets/', train=True, download=True,transform=transform)\n",
    "testdataset = datasets.CIFAR10('../datasets/', train=False, transform=transform)      \n",
    "from archs.cifar10 import AlexNet, LeNet5, fc1, vgg, resnet, densenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(traindataset, batch_size=args.batch_size, shuffle=True, num_workers=0,drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(testdataset, batch_size=args.batch_size, shuffle=False, num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global model\n",
    "model = resnet.resnet18().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Weight Initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    '''\n",
    "    Usage:\n",
    "        model = Model()\n",
    "        model.apply(weight_init)\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.LSTMCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRU):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRUCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(weight_init)\n",
    "\n",
    "# Copying and Saving Initial State\n",
    "initial_state_dict = copy.deepcopy(model.state_dict())\n",
    "utils.checkdir(f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/\")\n",
    "torch.save(model, f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/initial_state_dict_{args.prune_type}.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall that in the paper, they emphasized the importance of reusing the initialization of the original model weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Mask Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make an empty mask of the same size as the model\n",
    "def make_mask(model):\n",
    "    global step\n",
    "    global mask\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters(): \n",
    "        if 'weight' in name:\n",
    "            step = step + 1\n",
    "    mask = [None]* step # first, create a stack with None; each element would correspond to each weight in the model\n",
    "    \n",
    "    step = 0\n",
    "    for name, param in model.named_parameters(): \n",
    "        if 'weight' in name:\n",
    "            tensor = param.data.cpu().numpy()\n",
    "            mask[step] = np.ones_like(tensor) # then we filled up with tensor shape same as the corresponding weight, with value 1; just like how we did in the previous example\n",
    "            step = step + 1\n",
    "    step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mask(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the only difference is they made the mask outside the model whereas the previous implementation puts mask in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. defining optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss() # Default was F.nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. function to recover the original initial weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_initialization(mask_temp, initial_state_dict):\n",
    "    global model\n",
    "    \n",
    "    step = 0\n",
    "    for name, param in model.named_parameters(): \n",
    "        if \"weight\" in name: \n",
    "            weight_dev = param.device\n",
    "            param.data = torch.from_numpy(mask_temp[step] * initial_state_dict[name].cpu().numpy()).to(weight_dev)\n",
    "            step = step + 1\n",
    "        if \"bias\" in name:\n",
    "            param.data = initial_state_dict[name]\n",
    "    step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. functions for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    EPS = 1e-6\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        #imgs, targets = next(train_loader)\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        output = model(imgs)\n",
    "        train_loss = criterion(output, targets)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Freezing Pruned weights by making their gradients Zero\n",
    "        for name, p in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                tensor = p.data.cpu().numpy()\n",
    "                grad_tensor = p.grad.data.cpu().numpy()\n",
    "                grad_tensor = np.where(tensor < EPS, 0, grad_tensor) # if the weight is lower than EPS, just set to 0\n",
    "                p.grad.data = torch.from_numpy(grad_tensor).to(device)\n",
    "        optimizer.step()\n",
    "    return train_loss.item()\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. function for pruning by percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_by_percentile(percent, resample=False, reinit=False,**kwargs):\n",
    "    global step\n",
    "    global mask\n",
    "    global model\n",
    "\n",
    "    # Calculate percentile value\n",
    "    step = 0\n",
    "    for name, param in model.named_parameters():\n",
    "\n",
    "        # We do not prune bias term\n",
    "        if 'weight' in name:\n",
    "            tensor = param.data.cpu().numpy()\n",
    "            alive = tensor[np.nonzero(tensor)] # flattened array of nonzero values\n",
    "            percentile_value = np.percentile(abs(alive), percent)\n",
    "\n",
    "            # Convert Tensors to numpy and calculate\n",
    "            weight_dev = param.device\n",
    "            new_mask = np.where(abs(tensor) < percentile_value, 0, mask[step])\n",
    "\n",
    "            # Apply new weight and mask\n",
    "            param.data = torch.from_numpy(tensor * new_mask).to(weight_dev)\n",
    "            mask[step] = new_mask\n",
    "            step += 1\n",
    "    step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE First Pruning Iteration is of No Compression\n",
    "bestacc = 0.0\n",
    "best_accuracy = 0\n",
    "ITERATION = args.prune_iterations\n",
    "comp = np.zeros(ITERATION,float)\n",
    "bestacc = np.zeros(ITERATION,float)\n",
    "step = 0\n",
    "all_loss = np.zeros(args.end_iter,float)\n",
    "all_accuracy = np.zeros(args.end_iter,float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplification of code below <br>\n",
    "<br>\n",
    "for (pruning iteration):<br>\n",
    " >   if first, pass else prune <br>\n",
    "  >  for (training iteration):<br>\n",
    "   >>     train the model<br>\n",
    "     >>   compute loss and accuracy<br>\n",
    "  >  plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pruning Level [1:0/5]: ---\n",
      "conv1.weight         | nonzeros =    1728 /    1728 (100.00%) | total_pruned =       0 | shape = (64, 3, 3, 3)\n",
      "bn1.weight           | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)\n",
      "bn1.bias             | nonzeros =       0 /      64 (  0.00%) | total_pruned =      64 | shape = (64,)\n",
      "layer1.0.conv1.weight | nonzeros =   36864 /   36864 (100.00%) | total_pruned =       0 | shape = (64, 64, 3, 3)\n",
      "layer1.0.bn1.weight  | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)\n",
      "layer1.0.bn1.bias    | nonzeros =       0 /      64 (  0.00%) | total_pruned =      64 | shape = (64,)\n",
      "layer1.0.conv2.weight | nonzeros =   36864 /   36864 (100.00%) | total_pruned =       0 | shape = (64, 64, 3, 3)\n",
      "layer1.0.bn2.weight  | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)\n",
      "layer1.0.bn2.bias    | nonzeros =       0 /      64 (  0.00%) | total_pruned =      64 | shape = (64,)\n",
      "layer1.1.conv1.weight | nonzeros =   36864 /   36864 (100.00%) | total_pruned =       0 | shape = (64, 64, 3, 3)\n",
      "layer1.1.bn1.weight  | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)\n",
      "layer1.1.bn1.bias    | nonzeros =       0 /      64 (  0.00%) | total_pruned =      64 | shape = (64,)\n",
      "layer1.1.conv2.weight | nonzeros =   36864 /   36864 (100.00%) | total_pruned =       0 | shape = (64, 64, 3, 3)\n",
      "layer1.1.bn2.weight  | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)\n",
      "layer1.1.bn2.bias    | nonzeros =       0 /      64 (  0.00%) | total_pruned =      64 | shape = (64,)\n",
      "layer2.0.conv1.weight | nonzeros =   73728 /   73728 (100.00%) | total_pruned =       0 | shape = (128, 64, 3, 3)\n",
      "layer2.0.bn1.weight  | nonzeros =     128 /     128 (100.00%) | total_pruned =       0 | shape = (128,)\n",
      "layer2.0.bn1.bias    | nonzeros =       0 /     128 (  0.00%) | total_pruned =     128 | shape = (128,)\n",
      "layer2.0.conv2.weight | nonzeros =  147456 /  147456 (100.00%) | total_pruned =       0 | shape = (128, 128, 3, 3)\n",
      "layer2.0.bn2.weight  | nonzeros =     128 /     128 (100.00%) | total_pruned =       0 | shape = (128,)\n",
      "layer2.0.bn2.bias    | nonzeros =       0 /     128 (  0.00%) | total_pruned =     128 | shape = (128,)\n",
      "layer2.0.shortcut.0.weight | nonzeros =    8192 /    8192 (100.00%) | total_pruned =       0 | shape = (128, 64, 1, 1)\n",
      "layer2.0.shortcut.1.weight | nonzeros =     128 /     128 (100.00%) | total_pruned =       0 | shape = (128,)\n",
      "layer2.0.shortcut.1.bias | nonzeros =       0 /     128 (  0.00%) | total_pruned =     128 | shape = (128,)\n",
      "layer2.1.conv1.weight | nonzeros =  147456 /  147456 (100.00%) | total_pruned =       0 | shape = (128, 128, 3, 3)\n",
      "layer2.1.bn1.weight  | nonzeros =     128 /     128 (100.00%) | total_pruned =       0 | shape = (128,)\n",
      "layer2.1.bn1.bias    | nonzeros =       0 /     128 (  0.00%) | total_pruned =     128 | shape = (128,)\n",
      "layer2.1.conv2.weight | nonzeros =  147456 /  147456 (100.00%) | total_pruned =       0 | shape = (128, 128, 3, 3)\n",
      "layer2.1.bn2.weight  | nonzeros =     128 /     128 (100.00%) | total_pruned =       0 | shape = (128,)\n",
      "layer2.1.bn2.bias    | nonzeros =       0 /     128 (  0.00%) | total_pruned =     128 | shape = (128,)\n",
      "layer3.0.conv1.weight | nonzeros =  294912 /  294912 (100.00%) | total_pruned =       0 | shape = (256, 128, 3, 3)\n",
      "layer3.0.bn1.weight  | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
      "layer3.0.bn1.bias    | nonzeros =       0 /     256 (  0.00%) | total_pruned =     256 | shape = (256,)\n",
      "layer3.0.conv2.weight | nonzeros =  589824 /  589824 (100.00%) | total_pruned =       0 | shape = (256, 256, 3, 3)\n",
      "layer3.0.bn2.weight  | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
      "layer3.0.bn2.bias    | nonzeros =       0 /     256 (  0.00%) | total_pruned =     256 | shape = (256,)\n",
      "layer3.0.shortcut.0.weight | nonzeros =   32768 /   32768 (100.00%) | total_pruned =       0 | shape = (256, 128, 1, 1)\n",
      "layer3.0.shortcut.1.weight | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
      "layer3.0.shortcut.1.bias | nonzeros =       0 /     256 (  0.00%) | total_pruned =     256 | shape = (256,)\n",
      "layer3.1.conv1.weight | nonzeros =  589824 /  589824 (100.00%) | total_pruned =       0 | shape = (256, 256, 3, 3)\n",
      "layer3.1.bn1.weight  | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
      "layer3.1.bn1.bias    | nonzeros =       0 /     256 (  0.00%) | total_pruned =     256 | shape = (256,)\n",
      "layer3.1.conv2.weight | nonzeros =  589824 /  589824 (100.00%) | total_pruned =       0 | shape = (256, 256, 3, 3)\n",
      "layer3.1.bn2.weight  | nonzeros =     256 /     256 (100.00%) | total_pruned =       0 | shape = (256,)\n",
      "layer3.1.bn2.bias    | nonzeros =       0 /     256 (  0.00%) | total_pruned =     256 | shape = (256,)\n",
      "layer4.0.conv1.weight | nonzeros = 1179648 / 1179648 (100.00%) | total_pruned =       0 | shape = (512, 256, 3, 3)\n",
      "layer4.0.bn1.weight  | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
      "layer4.0.bn1.bias    | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)\n",
      "layer4.0.conv2.weight | nonzeros = 2359296 / 2359296 (100.00%) | total_pruned =       0 | shape = (512, 512, 3, 3)\n",
      "layer4.0.bn2.weight  | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
      "layer4.0.bn2.bias    | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)\n",
      "layer4.0.shortcut.0.weight | nonzeros =  131072 /  131072 (100.00%) | total_pruned =       0 | shape = (512, 256, 1, 1)\n",
      "layer4.0.shortcut.1.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
      "layer4.0.shortcut.1.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)\n",
      "layer4.1.conv1.weight | nonzeros = 2359296 / 2359296 (100.00%) | total_pruned =       0 | shape = (512, 512, 3, 3)\n",
      "layer4.1.bn1.weight  | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
      "layer4.1.bn1.bias    | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)\n",
      "layer4.1.conv2.weight | nonzeros = 2359296 / 2359296 (100.00%) | total_pruned =       0 | shape = (512, 512, 3, 3)\n",
      "layer4.1.bn2.weight  | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)\n",
      "layer4.1.bn2.bias    | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)\n",
      "linear.weight        | nonzeros =    5120 /    5120 (100.00%) | total_pruned =       0 | shape = (10, 512)\n",
      "linear.bias          | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
      "alive: 11169162, pruned : 4800, total: 11173962, Compression rate :       1.00x  (  0.04% pruned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/10 Loss: 2.078833 Accuracy: 13.53% Best Accuracy: 13.53%:  20%|██        | 2/10 [04:36<18:25, 138.16s/it]"
     ]
    }
   ],
   "source": [
    "for _ite in range(args.start_iter, ITERATION):\n",
    "    if not _ite == 0: # we first train;, then prune\n",
    "        prune_by_percentile(args.prune_percent, resample=resample, reinit=reinit)\n",
    "        if reinit:\n",
    "            model.apply(weight_init)\n",
    "            step = 0\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    weight_dev = param.device\n",
    "                    param.data = torch.from_numpy(param.data.cpu().numpy() * mask[step]).to(weight_dev)\n",
    "                    step = step + 1\n",
    "            step = 0\n",
    "        else:\n",
    "            original_initialization(mask, initial_state_dict)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    print(f\"\\n--- Pruning Level [{1}:{_ite}/{ITERATION}]: ---\")\n",
    "\n",
    "    # Print the table of Nonzeros in each layer\n",
    "    comp1 = utils.print_nonzeros(model)\n",
    "    comp[_ite] = comp1\n",
    "    pbar = tqdm(range(args.end_iter))\n",
    "\n",
    "    for iter_ in pbar:\n",
    "\n",
    "        # Frequency for Testing\n",
    "        if iter_ % args.valid_freq == 0:\n",
    "            accuracy = test(model, test_loader, criterion)\n",
    "\n",
    "            # Save Weights\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                utils.checkdir(f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/\")\n",
    "                torch.save(model,f\"{os.getcwd()}/saves/{args.arch_type}/{args.dataset}/{_ite}_model_{args.prune_type}.pth.tar\")\n",
    "\n",
    "        # Training\n",
    "        loss = train(model, train_loader, optimizer, criterion)\n",
    "        all_loss[iter_] = loss\n",
    "        all_accuracy[iter_] = accuracy\n",
    "\n",
    "        # Frequency for Printing Accuracy and Loss\n",
    "        if iter_ % args.print_freq == 0:\n",
    "            pbar.set_description(\n",
    "                f'Train Epoch: {iter_}/{args.end_iter} Loss: {loss:.6f} Accuracy: {accuracy:.2f}% Best Accuracy: {best_accuracy:.2f}%')       \n",
    "\n",
    "    writer.add_scalar('Accuracy/test', best_accuracy, comp1)\n",
    "    bestacc[_ite]=best_accuracy\n",
    "    \n",
    "    # Plotting Loss (Training), Accuracy (Testing), Iteration Curve\n",
    "    #NOTE Loss is computed for every iteration while Accuracy is computed only for every {args.valid_freq} iterations. Therefore Accuracy saved is constant during the uncomputed iterations.\n",
    "    #NOTE Normalized the accuracy to [0,100] for ease of plotting.\n",
    "    plt.plot(np.arange(1,(args.end_iter)+1), 100*(all_loss - np.min(all_loss))/np.ptp(all_loss).astype(float), c=\"blue\", label=\"Loss\") \n",
    "    plt.plot(np.arange(1,(args.end_iter)+1), all_accuracy, c=\"red\", label=\"Accuracy\") \n",
    "    plt.title(f\"Loss Vs Accuracy Vs Iterations ({args.dataset},{args.arch_type})\") \n",
    "    plt.xlabel(\"Iterations\") \n",
    "    plt.ylabel(\"Loss and Accuracy\") \n",
    "    plt.legend() \n",
    "    plt.grid(color=\"gray\") \n",
    "    utils.checkdir(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/\")\n",
    "    plt.savefig(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_LossVsAccuracy_{comp1}.png\", dpi=1200) \n",
    "    plt.close()\n",
    "\n",
    "    # Dump Plot values\n",
    "    utils.checkdir(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/\")\n",
    "    all_loss.dump(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_all_loss_{comp1}.dat\")\n",
    "    all_accuracy.dump(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_all_accuracy_{comp1}.dat\")\n",
    "\n",
    "    # Dumping mask\n",
    "    utils.checkdir(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/\")\n",
    "    with open(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_mask_{comp1}.pkl\", 'wb') as fp:\n",
    "        pickle.dump(mask, fp)\n",
    "\n",
    "    # Making variables into 0\n",
    "    best_accuracy = 0\n",
    "    all_loss = np.zeros(args.end_iter,float)\n",
    "    all_accuracy = np.zeros(args.end_iter,float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping Values for Plotting\n",
    "utils.checkdir(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/\")\n",
    "comp.dump(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_compression.dat\")\n",
    "bestacc.dump(f\"{os.getcwd()}/dumps/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_bestaccuracy.dat\")\n",
    "\n",
    "# Plotting\n",
    "a = np.arange(args.prune_iterations)\n",
    "plt.plot(a, bestacc, c=\"blue\", label=\"Winning tickets\") \n",
    "plt.title(f\"Test Accuracy vs Unpruned Weights Percentage ({args.dataset},{args.arch_type})\") \n",
    "plt.xlabel(\"Unpruned Weights Percentage\") \n",
    "plt.ylabel(\"test accuracy\") \n",
    "plt.xticks(a, comp, rotation =\"vertical\") \n",
    "plt.ylim(0,100)\n",
    "plt.legend() \n",
    "plt.grid(color=\"gray\") \n",
    "utils.checkdir(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/\")\n",
    "plt.savefig(f\"{os.getcwd()}/plots/lt/{args.arch_type}/{args.dataset}/{args.prune_type}_AccuracyVsWeights.png\", dpi=1200) \n",
    "plt.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pruning",
   "language": "python",
   "name": "pruning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
