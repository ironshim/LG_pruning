{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNIP: Single-shot Network Pruning based on Connection Sensitivity, 19`ICLR\n",
    "#### code mainly dependent on https://github.com/mil-ad/snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR10 dataset, VGG-16 model (138 M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import types\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision import transforms\n",
    "\n",
    "#from tensorboardX import SummaryWriter\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "\n",
    "from snip import snip_forward_conv2d, snip_forward_linear\n",
    "from train import cifar10_experiment, apply_prune_mask\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_INTERVAL = 20\n",
    "INIT_LR = 0.1\n",
    "WEIGHT_DECAY_RATE = 0.0005\n",
    "EPOCHS = 100  # originally 250\n",
    "REPEAT_WITH_DIFFERENT_SEED = 1\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LR_DECAY_INTERVAL = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNIP algorithm\n",
    "\n",
    "1. 1개의 minibatch 샘플링\n",
    "2. 모델 파라미터 (weight) variance scaling initialization\n",
    "3. loss의 c에 대한 gradient를 구해서 connection sensitivity 계산\n",
    "4. connection sensitivity sorting 후 pruning (top-k)\n",
    "5. 프루닝된 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snip_forward_conv2d(self, x):\n",
    "        return F.conv2d(x, self.weight * self.weight_mask, self.bias,\n",
    "                        self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "def snip_forward_linear(self, x):\n",
    "        return F.linear(x, self.weight * self.weight_mask, self.bias)\n",
    "    \n",
    "\n",
    "def SNIP(net, keep_ratio, train_dataloader, device):\n",
    "    inputs, targets = next(iter(train_dataloader))  # batch 1개 샘플링\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Let's create a fresh copy of the network so that we're not worried about\n",
    "    # affecting the actual training-phase\n",
    "    net = copy.deepcopy(net)\n",
    "\n",
    "    # Monkey-patch the Linear and Conv2d layer to learn the multiplicative mask\n",
    "    # instead of the weights\n",
    "    for layer in net.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight))  # auxiliary variable c -> 학습할 수 있는 parameter\n",
    "            nn.init.xavier_normal_(layer.weight)   # or kaiming_normal_()\n",
    "            layer.weight.requires_grad = False   # weight에 대한 gradient는 필요 없음.\n",
    "\n",
    "        # Override the forward methods:\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
    "\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            layer.forward = types.MethodType(snip_forward_linear, layer)\n",
    "\n",
    "    # Compute gradients (but don't apply them)\n",
    "    net.zero_grad()\n",
    "    outputs = net.forward(inputs)\n",
    "    loss = F.nll_loss(outputs, targets)\n",
    "    loss.backward()\n",
    "\n",
    "    grads_abs = []\n",
    "    for layer in net.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            grads_abs.append(torch.abs(layer.weight_mask.grad))\n",
    "\n",
    "    # Gather all scores in a single vector and normalise\n",
    "    all_scores = torch.cat([torch.flatten(x) for x in grads_abs])\n",
    "    norm_factor = torch.sum(all_scores)\n",
    "    all_scores.div_(norm_factor)\n",
    "\n",
    "    num_params_to_keep = int(len(all_scores) * keep_ratio)\n",
    "    threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\n",
    "    acceptable_score = threshold[-1]\n",
    "\n",
    "    keep_masks = []\n",
    "    for g in grads_abs:\n",
    "        keep_masks.append(((g / norm_factor) >= acceptable_score).float())\n",
    "\n",
    "    print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\n",
    "\n",
    "    return keep_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "tensor(761993, device='cuda:0')\n",
      "Pruning is done in 3.16 sec.\n"
     ]
    }
   ],
   "source": [
    "net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment(device)\n",
    "\n",
    "# Pre-training pruning using SNIP\n",
    "t = time.time()\n",
    "keep_masks = SNIP(net, 0.05, train_loader, device)  # 95% pruning\n",
    "apply_prune_mask(net, keep_masks)\n",
    "print('Pruning is done in {:.2f} sec.'.format(time.time()-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = SummaryWriter()\n",
    "trainer = create_supervised_trainer(net, optimiser, F.nll_loss, device)\n",
    "evaluator = create_supervised_evaluator(net, {\n",
    "    'accuracy': Accuracy(),\n",
    "    'nll': Loss(F.nll_loss)\n",
    "}, device)\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.attach(trainer)\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    lr_scheduler.step()\n",
    "    iter_in_epoch = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "#     if engine.state.iteration % LOG_INTERVAL == 0:\n",
    "#         # pbar.log_message(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "#         #       \"\".format(engine.state.epoch, iter_in_epoch, len(train_loader), engine.state.output))\n",
    "#         writer.add_scalar(\"training/loss\", engine.state.output,\n",
    "#                           engine.state.iteration)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_epoch(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_nll = metrics['nll']\n",
    "\n",
    "    # pbar.log_message(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "    #       .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
    "\n",
    "#     writer.add_scalar(\"validation/loss\", avg_nll, engine.state.iteration)\n",
    "#     writer.add_scalar(\"validation/accuracy\", avg_accuracy,\n",
    "#                       engine.state.iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_loader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
